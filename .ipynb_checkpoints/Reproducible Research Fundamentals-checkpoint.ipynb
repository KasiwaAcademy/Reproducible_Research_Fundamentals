{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5789a6ba-b531-49df-90b2-6f3b488d9ffe",
   "metadata": {},
   "source": [
    "# Processing Data for Reproducible Analytics\n",
    "\n",
    "## Explore the Data \n",
    "\n",
    "Begin by importing the required **Python** libraries and loading the **TZA_CCT_baseline.csv** dataset into Python. Following this, conduct a thorough inspection of the dataset to understand its structure and key characteristics. This inspection will be crucial for identifying the **Unit of Observation**, the **Unique ID**, the **Data Types**, and for gaining a rapid understanding of any potential **missing values** within the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe194278-dd0b-47e0-a086-d382f4083f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1760 entries, 0 to 1759\n",
      "Data columns (total 36 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   vid               1760 non-null   int64  \n",
      " 1   hhid              1760 non-null   int64  \n",
      " 2   enid              1760 non-null   int64  \n",
      " 3   floor             1760 non-null   int64  \n",
      " 4   roof              1760 non-null   int64  \n",
      " 5   walls             1760 non-null   int64  \n",
      " 6   water             1760 non-null   int64  \n",
      " 7   enegry            1760 non-null   int64  \n",
      " 8   rel_head          1760 non-null   int64  \n",
      " 9   female_head       1760 non-null   int64  \n",
      " 10  hh_size           1760 non-null   int64  \n",
      " 11  n_child_5         1760 non-null   int64  \n",
      " 12  n_child_17        1760 non-null   int64  \n",
      " 13  n_adult           1760 non-null   int64  \n",
      " 14  n_elder           1760 non-null   int64  \n",
      " 15  read              1759 non-null   float64\n",
      " 16  sick              1760 non-null   int64  \n",
      " 17  food_cons         1760 non-null   float64\n",
      " 18  nonfood_cons      1760 non-null   int64  \n",
      " 19  farm              1760 non-null   int64  \n",
      " 20  ar_farm           1622 non-null   float64\n",
      " 21  ar_farm_unit      1622 non-null   object \n",
      " 22  crop              1622 non-null   float64\n",
      " 23  crop_other        99 non-null     object \n",
      " 24  crop_prp          1511 non-null   float64\n",
      " 25  livestock_now     1760 non-null   int64  \n",
      " 26  livestock_before  1760 non-null   int64  \n",
      " 27  drought_flood     1760 non-null   int64  \n",
      " 28  crop_damage       1760 non-null   int64  \n",
      " 29  trust_mem         1760 non-null   int64  \n",
      " 30  trust_lead        1760 non-null   int64  \n",
      " 31  assoc             1760 non-null   int64  \n",
      " 32  health            1760 non-null   int64  \n",
      " 33  duration          1760 non-null   int64  \n",
      " 34  submissionday     1760 non-null   object \n",
      " 35  key               1760 non-null   object \n",
      "dtypes: float64(5), int64(27), object(4)\n",
      "memory usage: 495.1+ KB\n"
     ]
    }
   ],
   "source": [
    "## Import Libraries, Load in Data, and Initiate Data Exploration ##\n",
    "\n",
    "# Pandas and Numpy for Data Manipulation, Analysis, and Numerical Calculations \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Matplotlib and Seaborn for Data Visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set Visualisation Theme\n",
    "sns.set_theme()\n",
    "\n",
    "# Load in the Data \n",
    "baseline = pd.read_csv('Data/Raw/TZA_CCT_baseline.csv')\n",
    "\n",
    "# Set the display option so that output display a maximum of 100 columns ##\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "# Switch off warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(action = 'ignore')\n",
    "\n",
    "# Display the structure of the dataset\n",
    "baseline.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca06e62-3b65-4c54-9777-3f33dd884b0e",
   "metadata": {},
   "source": [
    "Analysis of the output reveals **1760** observations and **36** variables within the dataset. The data types include **27** integer (int64) columns, **4** string (object) columns, and **5** floating-point columns. The presence of missing values is evident in columns with fewer **non-null** entries. \n",
    "\n",
    "Examining the first **3** rows of the dataset will assist in determining the **unit of observation** and the **unique ID**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a6afa0c-3c52-4bf8-9606-1e3baafe2ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   vid  hhid  enid  floor  roof  walls  water  enegry  rel_head  female_head  \\\n",
      "0    1  9122   818      1     2      1      1       1         4            0   \n",
      "1    1  9111   420      1     2      1      4       1         4            1   \n",
      "2    1  9120   805      1     2      1      7       1         4            0   \n",
      "\n",
      "   hh_size  n_child_5  n_child_17  n_adult  n_elder  read  sick  food_cons  \\\n",
      "0        4          0           1        1        2   0.0     1   595400.0   \n",
      "1       10          1           3        3        3   0.0     0  1955200.0   \n",
      "2        2          0           0        1        1   1.0     0   183820.0   \n",
      "\n",
      "   nonfood_cons  farm   ar_farm ar_farm_unit  crop     crop_other  crop_prp  \\\n",
      "0         13600     1  0.500000         Acre  77.0            NaN       NaN   \n",
      "1         69926     1  1.214083      Hectare  99.0  Coconut trees       2.0   \n",
      "2          7500     1  0.250000         Acre  99.0         sesame       1.0   \n",
      "\n",
      "   livestock_now  livestock_before  drought_flood  crop_damage  trust_mem  \\\n",
      "0              0                10              0            0          0   \n",
      "1             19                21              1            1          1   \n",
      "2              6                 0              0            1          1   \n",
      "\n",
      "   trust_lead  assoc  health  duration        submissionday            key  \n",
      "0           0      1       1        66  2009-02-27 16:00:58  fxy1870677Fzo  \n",
      "1           1    -88       0       111  2009-02-28 11:14:02  ojM1236794YFp  \n",
      "2           1      0       0        77  2009-02-28 13:06:08  YTf1575975ERA  \n"
     ]
    }
   ],
   "source": [
    "# Display the first five rows of the dataset\n",
    "print(baseline.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f38683-c051-4089-b3b3-c110601811cb",
   "metadata": {},
   "source": [
    "Analyzing the dataset's nature and structure, the **unit of observation** appears to be the **Household**. The variables consistently describe household characteristics, and each observation clearly corresponds to a single household. There is no evidence suggesting multiple units of observation.\n",
    "\n",
    "Unique ID = **hhid**\n",
    "\n",
    "## Identify and Fix Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1111b4ec-b2b4-4a68-9e76-1a0fc9365ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Dataset has 2 duplicates.\n"
     ]
    }
   ],
   "source": [
    "# Identify duplicate by \"hhid\" column\n",
    "duplicates = baseline['hhid'].duplicated().sum()\n",
    "\n",
    "# Display the number of duplicates in the dataset\n",
    "print(f\"The Dataset has {duplicates} duplicates.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0805c10b-8426-40f9-a712-8397c1d0e840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new number of duplicated observation is: 0.\n"
     ]
    }
   ],
   "source": [
    "# Drop Duplicates -- the code will drop duplicates \n",
    "baseline.drop_duplicates(subset = ['hhid'], ignore_index = True, inplace = True)\n",
    "\n",
    "# Check if indeed duplicates have been deleted \n",
    "new_duplicates = baseline['hhid'].duplicated().sum()\n",
    "print(f\"The new number of duplicated observation is: {new_duplicates}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9ed997-2e4f-4ec2-87d2-2c2358b6bfb9",
   "metadata": {},
   "source": [
    "## Clean the Data  \n",
    "\n",
    "### Replace numeric values representing missing data (-88) with missings.\n",
    "\n",
    "To address the presence of **-88** as a missing value indicator, these values will be replaced with **NaN**, the standard Python representation for missing data. Before applying the replacement, we will display the first five rows of a representative column containing **-88** to serve as a baseline for verification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2b86075-8190-44e4-b74d-9982511279b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     1\n",
      "1   -88\n",
      "2     0\n",
      "3     0\n",
      "4     0\n",
      "Name: assoc, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Display the first five rows of \"assoc\" column\n",
    "print(baseline['assoc'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b1e5ca8-bb8d-4cd5-a754-b1a551fe1a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1.0\n",
      "1    NaN\n",
      "2    0.0\n",
      "3    0.0\n",
      "4    0.0\n",
      "Name: assoc, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Replace numeric values representing missing data (-88) with NaN values.\n",
    "baseline.replace(-88, np.nan, inplace = True)\n",
    "\n",
    "# Display the \"assoc\" column again to check if the changes made are successful\n",
    "print(baseline['assoc'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2812fb11-8feb-454c-baac-88608099ede0",
   "metadata": {},
   "source": [
    "The **-88** values have successfully been replaced with **NaN** as indicated in the `assoc` column snipet above. \n",
    "\n",
    "### Extend the values in `crop` column by adding the two most used categories from `crop_other`.\n",
    "\n",
    "Before anything else, It is import to create a **Frequency Table** for `crop_other` column to check its **unique** values and their corresponding frequencies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03fde8b3-d108-4d3a-a14f-d5dfa19984d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The unique values for crop_other are:\n",
      " crop_other\n",
      "NaN               1659\n",
      "sesame              31\n",
      "Sesame              25\n",
      "Sesame.             24\n",
      "Coconut             15\n",
      "Coconut.             2\n",
      "Coconut trees        1\n",
      "Coconut trees.       1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Creating frequency distribution table for crop_other\" column\n",
    "crop_other_freq = baseline['crop_other'].value_counts(dropna = False)\n",
    "\n",
    "# Display the unique values\n",
    "print(f\"The unique values for crop_other are:\\n {crop_other_freq}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43096387-1780-4faf-9883-5fb271343fdc",
   "metadata": {},
   "source": [
    "As evidenced by the table, this column exhibits inconsistent data entries. It contains a mix of intended missing value indicators, specific entries like **Seseme** and **Coconut**, and numerous typographical errors. Therefore, it is essential to clean this column before proceeding with any data extensions or modifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12034fa7-06bc-4d61-8276-d282f3fd429b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new frequency table for crop_other is:\n",
      " crop_other\n",
      "NaN        1659\n",
      "Sesame       80\n",
      "Coconut      19\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Map old values to new values - Cleaning \"crop_other\" column\n",
    "map = {'sesame': 'Sesame', 'Sesame.': 'Sesame', 'Sesame': 'Sesame', 'Coconut.':\\\n",
    "       'Coconut', 'Coconut trees': 'Coconut', 'Coconut trees.': 'Coconut', 'Coconut': 'Coconut'}\n",
    "\n",
    "# Map Inconsistent values to correct values\n",
    "baseline['crop_other'] = baseline['crop_other'].map(map)\n",
    "\n",
    "# Display the new frequency table to check if the column has been cleaned\n",
    "crop_other_freq = baseline['crop_other'].value_counts(dropna = False)\n",
    "print(f\"The new frequency table for crop_other is:\\n {crop_other_freq}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2b7712-70ca-4c2b-8ec1-03c8be3b2eaa",
   "metadata": {},
   "source": [
    "The `crop_other` column is now cleaned and ready for further analysis. The next step is to augment the `crop` column by incorporating the two most common entries from `crop_other`. To better understand the interplay between these columns, the following is a table snippet that specifically highlights instances where `crop_other` contains **Sesame** or **Coconut**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c998674-e2de-4fb7-9506-13e4dbe90068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      crop crop_other\n",
      "1     99.0    Coconut\n",
      "2     99.0     Sesame\n",
      "1095  99.0     Sesame\n",
      "1261  99.0     Sesame\n",
      "666   99.0     Sesame\n",
      "1749  99.0    Coconut\n",
      "1266  99.0     Sesame\n",
      "668   99.0     Sesame\n",
      "66    99.0     Sesame\n",
      "1401  99.0    Coconut\n"
     ]
    }
   ],
   "source": [
    "df_crop = baseline[baseline['crop_other'].isin(['Sesame', 'Coconut'])][['crop', 'crop_other']]\n",
    "print(df_crop.sample(10, random_state = 45))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf20efdb-a517-4f3f-ba10-419524c0439a",
   "metadata": {},
   "source": [
    "Given that the `crop` column is intended as a numerical representation of the categorical values in `crop_other`, it's crucial that each unique category in `crop_other` has a unique numerical code in `crop`. To integrate 'Sesame' and 'Coconut' from crop_other into crop, it makes sense to assign them two previously unused numerical codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7439612-a58f-4137-929c-6c83f711f626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      crop crop_other\n",
      "1     41.0    Coconut\n",
      "2     40.0     Sesame\n",
      "1095  40.0     Sesame\n",
      "1261  40.0     Sesame\n",
      "666   40.0     Sesame\n",
      "1749  41.0    Coconut\n",
      "1266  40.0     Sesame\n",
      "668   40.0     Sesame\n",
      "66    40.0     Sesame\n",
      "1401  41.0    Coconut\n"
     ]
    }
   ],
   "source": [
    "### Extend the values in crop column by adding the two most used categories from crop_other\n",
    "baseline['crop'] = baseline['crop'].mask(baseline['crop_other'] == 'Sesame', 40)\n",
    "baseline['crop'] = baseline['crop'].mask(baseline['crop_other'] == 'Coconut', 41)\n",
    "\n",
    "# Verify if the values have indeed been changed\n",
    "df_crop = baseline[baseline['crop_other'].isin(['Sesame', 'Coconut'])][['crop', 'crop_other']]\n",
    "print(df_crop.sample(10, random_state = 45))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1d6340e-5b82-4b5c-9dff-b82734ae0fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The Unique values for 'crop' column are:\n",
      " [77. 41. 40.  6.  4.  9.  5. 34.  1. 15. nan 11. 32. 39.  3.  8. 21. 20.\n",
      " 24. 18. 10. 17. 31.  2. 13.]\n"
     ]
    }
   ],
   "source": [
    "# Display unique values for crop column to verify if \"99\" is realy gone\n",
    "crop_unique = baseline['crop'].unique()\n",
    "\n",
    "# Display the unique values\n",
    "print(f\"\\nThe Unique values for 'crop' column are:\\n {crop_unique}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198238b3-8156-4a55-9a39-7b806a677ae2",
   "metadata": {},
   "source": [
    "`crop` column and `crop_other` columns have successfully been cleaned.\n",
    "\n",
    "### Check and document if there are numeric variable that have outliers\n",
    "\n",
    "The following activities will check for otliers in **Consumption** and **Area variables**.\n",
    "\n",
    "**Consumption Varaibles**: `food_cons` and `nonfood_cons`\n",
    "\n",
    "**Area Variables**: `ar_farm`\n",
    "\n",
    "The first step is to generate the summary statistics for the three columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae6d51f8-3e59-4cb0-83af-44d26306cd1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary Statistics for 'Consumption' and 'Area' variables: \n",
      "\n",
      "           food_cons  nonfood_cons      ar_farm\n",
      "count  1.758000e+03  1.758000e+03  1620.000000\n",
      "mean   6.392233e+05  1.468731e+05     1.321132\n",
      "std    5.131717e+05  2.510197e+05     1.061838\n",
      "min    5.096000e+03  0.000000e+00     0.125000\n",
      "25%    2.616250e+05  2.347750e+04     1.000000\n",
      "50%    5.174000e+05  6.993300e+04     1.214083\n",
      "75%    8.580000e+05  1.665750e+05     2.000000\n",
      "max    4.903600e+06  4.108400e+06    32.375556\n"
     ]
    }
   ],
   "source": [
    "df_stats = baseline[['food_cons', 'nonfood_cons', 'ar_farm']].describe()\n",
    "print(f\"\\nSummary Statistics for 'Consumption' and 'Area' variables: \\n\\n {df_stats}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5d0547-ca2b-43f7-b6b7-0d951df14652",
   "metadata": {},
   "source": [
    "The summary statistics will facilitate the calculation of **interquartile** ranges (IQRs). These **IQR**s will subsequently be used to define **upper** and **lower** outlier **thresholds**. Data points that fall beyond these thresholds will be flagged as **outliers**.\n",
    "\n",
    "#### Check for outliers in `food_cons` column\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "171c9b69-32cc-472a-ae7b-4b6fb2f321db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " The number of Outliers in 'food_cons' columns is:\n",
      " 65\n"
     ]
    }
   ],
   "source": [
    "# Define a function that will be used forchecking for outliers in columns\n",
    "\n",
    "def get_outliers(data, column_name):\n",
    "    \n",
    "    # Generate Summary Statisticts for the winsorised columns\n",
    "    df_stats = data[column_name].describe()\n",
    "\n",
    "    # Determine the first Quartile (Q1) and Third Quartile (Q3)\n",
    "    Q1 = df_stats.loc['25%']\n",
    "    Q3 = df_stats.loc['75%']\n",
    "\n",
    "    # Calculate \"Interquatile\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    # Define the multiplier\n",
    "    multiplier = 1.5\n",
    "\n",
    "    # Calculate \"Upper\" and \"Lower\" Thresholds using IQR and multiplier\n",
    "    upper_threshold = Q3 + (IQR * multiplier)\n",
    "    lower_threshold = Q1 - (IQR * multiplier)\n",
    "\n",
    "    # Find Outliers\n",
    "    outliers = baseline[(data[column_name] > upper_threshold) | (data[column_name] < lower_threshold)][column_name]\n",
    "    return outliers\n",
    "    \n",
    "# Check for outlier in \"food_cons\" column\n",
    "food_cons_outliers = get_outliers(baseline, 'food_cons')\n",
    "\n",
    "# Display Outliers\n",
    "print(f\"\\n The number of Outliers in 'food_cons' columns is:\\n {food_cons_outliers.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a369b79a-c251-4ad0-8737-9fceb5f907b2",
   "metadata": {},
   "source": [
    "The output indicates that the column `food_cons` has **65** outliers.\n",
    "\n",
    "#### Check for outliers in `nonfood_cons` column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "08c7ce16-f618-42a5-a829-a568788615a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The number of Outliers in 'nonfood_cons' column is: \n",
      " 157\n"
     ]
    }
   ],
   "source": [
    "# Check for outliers in \"nonfood_cons\"\n",
    "nonfood_cons_outliers = get_outliers(baseline, 'nonfood_cons')\n",
    "# Display Outliers\n",
    "print(f\"\\nThe number of Outliers in 'nonfood_cons' column is: \\n {nonfood_cons_outliers.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e67c9e8-c185-4a2d-84eb-cc67ef81ccb0",
   "metadata": {},
   "source": [
    "`nonfood` column has **157** outliers.\n",
    "\n",
    "#### Check for outliers in `ar_farm` column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17e7cc0b-eb71-4091-a017-0723f9712879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The number of Outliers in 'ar_farm' column is:\n",
      " 21\n"
     ]
    }
   ],
   "source": [
    "# Check for outliers in \"ar_farm\" column\n",
    "ar_farm_outliers = get_outliers(baseline, 'ar_farm')\n",
    "# Display Outliers\n",
    "print(f\"\\nThe number of Outliers in 'ar_farm' column is:\\n {ar_farm_outliers.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65c3161-1c9b-41c4-b9c9-cfe666e424af",
   "metadata": {},
   "source": [
    "`ar_farm`column has **21** outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94afcb2-7855-4ca8-8fa1-06a083f0a4fa",
   "metadata": {},
   "source": [
    "## Saving the cleaned Dataset\n",
    "\n",
    "The cleaned dataset will be saved in Data/Intermediate folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a4da7d22-6c62-4208-9277-b9a4007a6ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline.to_csv(\"Data/Intermediate/TZA_CCT_baseline_new.csv\", encoding = \"utf8\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472fff7d-ac87-4cf3-bb11-d16f9162e296",
   "metadata": {},
   "source": [
    "# Preparing Data for Reproducible Analytics\n",
    "\n",
    "## Planning Construction Outputs\n",
    "\n",
    "In the preceding section, the focus was on data processing, primarily resolving data inconsistencies. Now, the attention is shifted to data preparation, a crucial step before analysis. This involves creating new variables and indicators from the existing data, ensuring the original dataset's relevance and credibility remain intact.\n",
    "\n",
    "The expexted construction outputs:\n",
    "\n",
    "1. A new variable `area_acre` which will be a standardised `ar_farm` variable containing values in **acres**.\n",
    "\n",
    "2. A new variable `food_cons_USD` which will contains `food_cons` values in **United States Dollars**.\n",
    "\n",
    "3. A new variable `nonfood_cons_USD` with `nonfood_cons` values in **United States Dollars**.\n",
    "\n",
    "4. A **merged** dataset ready for analysis.\n",
    "\n",
    "## Standardize Units for Land Area and Currencies\n",
    "    \n",
    "During data acquisition, land area was reportes in two units: **Acre** and **Hectare**. Consumption Variables, `food_cons` and `nonfood_cons`, were reported in **Tanzanian** Shillings. These need to be converted to standardized units for analysis. \n",
    "\n",
    "### Standardize Land Area to Acres\n",
    "                                                                                                            \n",
    "The `area_acre` column will be generated based on the `ar_farm` and `ar_farm_unit` columns. Specifically, if `ar_farm_unit` indicates **Acre**, the corresponding `ar_farm` value will be transferred to `area_acre`. Conversely, if `ar_farm_unit` indicates **Hectares**, the `ar_farm` value will be converted to acres by multiplying it by **2.47**, and the result will be stored in `area_acre`.                                                                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b49d1e31-b244-49fc-b784-1d9718938be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ar_farm  area_acre ar_farm_unit\n",
      "0  0.500000   0.500000         Acre\n",
      "1  1.214083   2.998786      Hectare\n",
      "2  0.250000   0.250000         Acre\n",
      "3  1.500000   1.500000         Acre\n",
      "4  1.000000   1.000000         Acre\n",
      "5  2.000000   2.000000         Acre\n",
      "6  1.000000   1.000000         Acre\n",
      "7  1.416431   3.498584      Hectare\n",
      "8  1.011736   2.498988      Hectare\n",
      "9  1.618778   3.998381      Hectare\n"
     ]
    }
   ],
   "source": [
    "# Conversion Factor\n",
    "hector_to_acre = 2.47\n",
    "\n",
    "# Define a function that will convert Hecters to Acres on condition\n",
    "def convert_to_acre(row):\n",
    "    if row['ar_farm_unit'] == 'Hectare':\n",
    "        return row['ar_farm'] * hector_to_acre\n",
    "    else:\n",
    "        return row['ar_farm']\n",
    "        \n",
    "# Creat \"area_acre\" column         \n",
    "baseline['area_acre'] = baseline.apply(convert_to_acre, axis = 1)\n",
    "\n",
    "# Display a snipet of the three \"area columns\" to check if the conversion has been successful\n",
    "print(baseline[['ar_farm', 'area_acre', 'ar_farm_unit']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19cee4be-36cc-4f58-98c6-cc4b77a4c93b",
   "metadata": {},
   "source": [
    "Now that the `area_acre` variable has been **constructed**, the next step is to standardize the currency as reported in `food_cons` and `nonfood_cons` columns.\n",
    "    \n",
    "### Standardize Currency to USD:\n",
    "    \n",
    "Consumption variable (`food_cons` and `nonfood_cons`) will be converted from **Tanzanian** Shillings to **USD**. New variables, `food_cons_usd` and `nonfood_cons_usd` will be genarated to contain the converted values. The following formula will be used for converting **TZS** to **USD**: $$ USD = \\left(\\frac{Tanzanian Shilling}{Exchange Rate}\\right)$$ \n",
    "                                                                                                                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bcc59a49-90ac-45f8-9aa9-c1f9224ee164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2619.26\n"
     ]
    }
   ],
   "source": [
    "## Exchange Rate\n",
    "\n",
    "# Define a function that fetches  the latest exchange rates to \"USD\" if supplied with currency code\n",
    "def exchange_rate(currency_code):\n",
    "     \n",
    "    # Import \"requests\" for naking HTTP requests to web servers\n",
    "    # It will be used for getting latest exchange rates\n",
    "    import requests\n",
    "     \n",
    "    # Import json for parsing HTTP response content as Json\n",
    "    import json\n",
    "\n",
    "    # Url to for exchange rate API\n",
    "    exchange_rate_api_url = 'https://api.exchangerate-api.com/v4/latest/usd'\n",
    "\n",
    "    # Make a request\n",
    "    response = requests.get(exchange_rate_api_url)\n",
    "    response = response.json()['rates']\n",
    "    return response[currency_code]    \n",
    "\n",
    "# Fetch Tanzanian Shilling exchange rate using the function\n",
    "TZS_per_usd = exchange_rate(currency_code = 'TZS')\n",
    "print(TZS_per_usd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5934d969-b8fd-40b6-a965-58e68645abd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   food_cons  nonfood_cons  food_cons_usd  nonfood_cons_usd\n",
      "0   595400.0         13600     227.316112          5.192306\n",
      "1  1955200.0         69926     746.470377         26.696853\n",
      "2   183820.0          7500      70.180127          2.863404\n",
      "3   373620.0         94000     142.643342         35.887999\n",
      "4  1006200.0        364600     384.154303        139.199621\n",
      "5  1014000.0         86400     387.132243         32.986416\n",
      "6  1842360.0        342630     703.389507        130.811756\n",
      "7  1669252.0        147501     637.299084         56.313997\n",
      "8   514800.0        117800     196.544062         44.974535\n",
      "9  1903200.0        553500     726.617442        211.319228\n"
     ]
    }
   ],
   "source": [
    "# Create \"food_cons_usd\" using the exchange rate calculated above and \"food_cons\" column\n",
    "baseline['food_cons_usd'] = baseline['food_cons'].apply(lambda x: x / TZS_per_usd)\n",
    "\n",
    "# Create \"nonfood_cons_usd\" using the exchange rate and \"nonfood_cons\" column\n",
    "baseline['nonfood_cons_usd'] = baseline['nonfood_cons'].apply(lambda x: x / TZS_per_usd)\n",
    "\n",
    "# Display a snippet of the Consumption variables to verify the changes\n",
    "print(baseline[['food_cons', 'nonfood_cons', 'food_cons_usd', 'nonfood_cons_usd']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95113eab-9ab4-4be7-954b-301fb5fde9d9",
   "metadata": {},
   "source": [
    "## Deal with Outliers \n",
    "\n",
    "To ensure data integrity before merging, **winsorization** will be used to manage outliers in the newly created columns. Specifically, the **5th** and **95th** percentile values will replace extreme values, balancing outlier reduction with the preservation of valuable high-value data points.\n",
    " \n",
    "For this activity, a **winsorize** method from **scipy** python Library will be used. The upper limits will initially be set at **95%** (0.05) and the lower limits at **5%** (0.05). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0b9a5474-7493-44f9-9cb4-4bce5e3d2f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import \"scipy\" Library\n",
    "import scipy.stats.mstats as sp\n",
    "\n",
    "# Winsorize \"area_acre\" column\n",
    "baseline['area_acre'] = sp.winsorize(baseline['area_acre'], limits = [0.05, 0.05])\n",
    "\n",
    "# Winsorize \"food_cons_usd\" column\n",
    "baseline['food_cons_usd'] = sp.winsorize(baseline['food_cons_usd'], limits = [0.05, 0.05])\n",
    "\n",
    "# Winsorize \"nonfood_cons_usd\" column\n",
    "baseline['nonfood_cons_usd'] = sp.winsorize(baseline['nonfood_cons_usd'], limits = [0.05, 0.05])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c33378-4e02-4ce9-ada5-b048a8591c2f",
   "metadata": {},
   "source": [
    "**Verify if the columns have successfully been winsorized.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a9f41967-4a7a-4ee4-8bf8-a6cb7db1e450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The new number of Outliers in 'food_cons' column is:\n",
      " 0\n"
     ]
    }
   ],
   "source": [
    "# Check for outliers in \"food_cons_usd\" column after winsorizing\n",
    "food_cons_usd_outliers = get_outliers(baseline, 'food_cons_usd')\n",
    "\n",
    "# Display Outliers\n",
    "print(f\"\\nThe new number of Outliers in 'food_cons' column is:\\n {food_cons_usd_outliers.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9411b606-ccca-4f06-9580-dac36f8a44f4",
   "metadata": {},
   "source": [
    "The `food_cons_usd` column is now free of the outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bf423ad5-e668-4cd7-965c-1e57da9a4717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The number of Outliers in 'nonfood_cons' column is:\n",
      " 157\n"
     ]
    }
   ],
   "source": [
    "# Check for outliers in \"nonfood_cons_usd\" column after winsorizing\n",
    "nonfood_cons_usd_outliers = get_outliers(baseline, 'nonfood_cons_usd')\n",
    "\n",
    "# Display Outliers\n",
    "print(f\"\\nThe number of Outliers in 'nonfood_cons' column is:\\n {nonfood_cons_usd_outliers.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4c88f9-cdfb-4020-a207-1b8f5d006258",
   "metadata": {},
   "source": [
    "The `nonfood_cons_usd` column still has outliers. Changing the lower limit to **10%** (0.1) and upper limit to **90%** (0.1) would do the magic of successfully **winsorizing** the outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "013fc625-52e3-42c5-8440-bb17cff0f828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The new number of Outliers in 'nonfood_cons' column is:\n",
      " 0\n"
     ]
    }
   ],
   "source": [
    "# Winsorize \"nonfood_cons_usd\" column - with limits changed to 0.1\n",
    "baseline['nonfood_cons_usd'] = sp.winsorize(baseline['nonfood_cons_usd'], limits = [0.1, 0.1])\n",
    "\n",
    "# Get the new outliers\n",
    "nonfood_cons_usd_outliers = get_outliers(baseline, 'nonfood_cons_usd')\n",
    "\n",
    "# Display Outliers again\n",
    "print(f\"\\nThe new number of Outliers in 'nonfood_cons' column is:\\n {nonfood_cons_usd_outliers.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f184816b-44d5-4239-b017-b7f492609e42",
   "metadata": {},
   "source": [
    "The `nonfood_cons_usd` outliers have successfully been **winsorized**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "94e8d2a0-cc62-4f42-a0b1-8b3f605b2129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The number of Outliers in 'area_acre' column is:\n",
      " 120\n"
     ]
    }
   ],
   "source": [
    "# Check for outliers in \"ar_farm\" column after winsorizing\n",
    "area_acre_outliers = get_outliers(baseline, 'area_acre')\n",
    "\n",
    "# Display Outliers\n",
    "print(f\"\\nThe number of Outliers in 'area_acre' column is:\\n {area_acre_outliers.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ba2f57-3678-4a16-bbac-597605c3b9b7",
   "metadata": {},
   "source": [
    "Standardizing the `area_acre` column resulted in a higher count of outliers. Therefore, winsorization with a 0.1 limit will be used to effectively address these outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3fa31dd8-87e7-47a6-b7b7-0dc5f87caeb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The new number of Outliers in 'area_acre' column is:\n",
      " 0\n"
     ]
    }
   ],
   "source": [
    "# Winsorize \"area_acre\" column - with limits changed to 0.1\n",
    "baseline['area_acre'] = sp.winsorize(baseline['area_acre'], limits = [0.1, 0.15])\n",
    "\n",
    "# Get the new outliers\n",
    "area_acre_outliers = get_outliers(baseline, 'area_acre')\n",
    "\n",
    "# Display Outliers again\n",
    "print(f\"\\nThe new number of Outliers in 'area_acre' column is:\\n {area_acre_outliers.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7caee184-3596-4082-a6d7-eef54f516718",
   "metadata": {},
   "source": [
    "Outliers have successfully been **Winsorized** from the `area_acre`column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf468c2b-18cf-4c30-8047-cb94e4f1fffa",
   "metadata": {},
   "source": [
    "## Merging Data\n",
    "\n",
    "Following data cleaning and feature engineering, the dataset will be merged with treat_status. This merge will produce a comprehensive dataset suitable for subsequent analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b27dd296-87b4-4fc5-89de-151146b7dbdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   vid  treatment  district district_name\n",
      "0    1          0         2      Bagamoyo\n",
      "1    2          1         2      Bagamoyo\n",
      "2    3          1         2      Bagamoyo\n",
      "3    4          0         2      Bagamoyo\n",
      "4    5          0         2      Bagamoyo\n"
     ]
    }
   ],
   "source": [
    "# Import the treat_status dataset\n",
    "treat_status = pd.read_csv('Data/Raw/treat_status.csv')\n",
    "\n",
    "# Display the first five rows\n",
    "print(treat_status.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8c520cc0-a898-43d4-bb48-60d3b13df8c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1758, 42)\n"
     ]
    }
   ],
   "source": [
    "# Merge \"baseline\" data with \"treat_status\" data on vid column\n",
    "combined = baseline.merge(treat_status, on = 'vid', how = 'left')\n",
    "\n",
    "# Display the number of rows and columns for the new dataset\n",
    "print(combined.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed337da-c52d-4ab5-9162-a27f8c0aac6b",
   "metadata": {},
   "source": [
    "After merging, the dataset maintains **1758** observations, while the column count has increased to **42**. This increase is attributed to the creation of new variables and the inclusion of columns from the **treat_status** dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb82e41-5454-4c17-8211-94fc57279e8b",
   "metadata": {},
   "source": [
    "## Saving Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f1f17ccb-26ab-4a3d-b1d6-b5e3972029c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.to_csv('Data/Final/baseline_treat_status.csv', encoding = 'utf8', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1f715b-cb0c-4c7b-9e95-038dbd1f677f",
   "metadata": {},
   "source": [
    "# Reproducible Data Analytics and Reporting"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
