{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5789a6ba-b531-49df-90b2-6f3b488d9ffe",
   "metadata": {},
   "source": [
    "# Processing Data for Reproducible Analytics\n",
    "\n",
    "## Explore the Data \n",
    "\n",
    "Begin by importing the required **Python** libraries and loading the **TZA_CCT_baseline.csv** dataset into Python. Following this, conduct a thorough inspection of the dataset to understand its structure and key characteristics. This inspection will be crucial for identifying the **Unit of Observation**, the **Unique ID**, the **Data Types**, and for gaining a rapid understanding of any potential **missing values** within the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe194278-dd0b-47e0-a086-d382f4083f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1760 entries, 0 to 1759\n",
      "Data columns (total 36 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   vid               1760 non-null   int64  \n",
      " 1   hhid              1760 non-null   int64  \n",
      " 2   enid              1760 non-null   int64  \n",
      " 3   floor             1760 non-null   int64  \n",
      " 4   roof              1760 non-null   int64  \n",
      " 5   walls             1760 non-null   int64  \n",
      " 6   water             1760 non-null   int64  \n",
      " 7   enegry            1760 non-null   int64  \n",
      " 8   rel_head          1760 non-null   int64  \n",
      " 9   female_head       1760 non-null   int64  \n",
      " 10  hh_size           1760 non-null   int64  \n",
      " 11  n_child_5         1760 non-null   int64  \n",
      " 12  n_child_17        1760 non-null   int64  \n",
      " 13  n_adult           1760 non-null   int64  \n",
      " 14  n_elder           1760 non-null   int64  \n",
      " 15  read              1759 non-null   float64\n",
      " 16  sick              1760 non-null   int64  \n",
      " 17  food_cons         1760 non-null   float64\n",
      " 18  nonfood_cons      1760 non-null   int64  \n",
      " 19  farm              1760 non-null   int64  \n",
      " 20  ar_farm           1622 non-null   float64\n",
      " 21  ar_farm_unit      1622 non-null   object \n",
      " 22  crop              1622 non-null   float64\n",
      " 23  crop_other        99 non-null     object \n",
      " 24  crop_prp          1511 non-null   float64\n",
      " 25  livestock_now     1760 non-null   int64  \n",
      " 26  livestock_before  1760 non-null   int64  \n",
      " 27  drought_flood     1760 non-null   int64  \n",
      " 28  crop_damage       1760 non-null   int64  \n",
      " 29  trust_mem         1760 non-null   int64  \n",
      " 30  trust_lead        1760 non-null   int64  \n",
      " 31  assoc             1760 non-null   int64  \n",
      " 32  health            1760 non-null   int64  \n",
      " 33  duration          1760 non-null   int64  \n",
      " 34  submissionday     1760 non-null   object \n",
      " 35  key               1760 non-null   object \n",
      "dtypes: float64(5), int64(27), object(4)\n",
      "memory usage: 495.1+ KB\n"
     ]
    }
   ],
   "source": [
    "## Import Libraries ##\n",
    "\n",
    "# Pandas and Numpy for Data Manipulation, Analysis, and Numerical Calculations \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Matplotlib and Seaborn for Data Visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set Visualisation Theme\n",
    "sns.set_theme()\n",
    "\n",
    "## Load in the Data ##\n",
    "df = pd.read_csv('Data/Raw/TZA_CCT_baseline.csv')\n",
    "\n",
    "## Set the display option so that output display a maximum of 100 columns ##\n",
    "pd.set_option('display.max_columns', 100)\n",
    "## Explore the Data ##\n",
    "\n",
    "# Display the structure of the dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca06e62-3b65-4c54-9777-3f33dd884b0e",
   "metadata": {},
   "source": [
    "Analysis of the output reveals **1760** observations and **36** variables within the dataset. The data types include **27** integer (int64) columns, **4** string (object) columns, and **5** floating-point columns. The presence of missing values is evident in columns with fewer **non-null** entries. \n",
    "\n",
    "Examining the first **3** rows of the dataset will assist in determining the **unit of observation** and the **unique ID**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a6afa0c-3c52-4bf8-9606-1e3baafe2ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   vid  hhid  enid  floor  roof  walls  water  enegry  rel_head  female_head  \\\n",
      "0    1  9122   818      1     2      1      1       1         4            0   \n",
      "1    1  9111   420      1     2      1      4       1         4            1   \n",
      "2    1  9120   805      1     2      1      7       1         4            0   \n",
      "\n",
      "   hh_size  n_child_5  n_child_17  n_adult  n_elder  read  sick  food_cons  \\\n",
      "0        4          0           1        1        2   0.0     1   595400.0   \n",
      "1       10          1           3        3        3   0.0     0  1955200.0   \n",
      "2        2          0           0        1        1   1.0     0   183820.0   \n",
      "\n",
      "   nonfood_cons  farm   ar_farm ar_farm_unit  crop     crop_other  crop_prp  \\\n",
      "0         13600     1  0.500000         Acre  77.0            NaN       NaN   \n",
      "1         69926     1  1.214083      Hectare  99.0  Coconut trees       2.0   \n",
      "2          7500     1  0.250000         Acre  99.0         sesame       1.0   \n",
      "\n",
      "   livestock_now  livestock_before  drought_flood  crop_damage  trust_mem  \\\n",
      "0              0                10              0            0          0   \n",
      "1             19                21              1            1          1   \n",
      "2              6                 0              0            1          1   \n",
      "\n",
      "   trust_lead  assoc  health  duration        submissionday            key  \n",
      "0           0      1       1        66  2009-02-27 16:00:58  fxy1870677Fzo  \n",
      "1           1    -88       0       111  2009-02-28 11:14:02  ojM1236794YFp  \n",
      "2           1      0       0        77  2009-02-28 13:06:08  YTf1575975ERA  \n"
     ]
    }
   ],
   "source": [
    "# Display the first five rows of the dataset\n",
    "print(df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f38683-c051-4089-b3b3-c110601811cb",
   "metadata": {},
   "source": [
    "Analyzing the dataset's nature and structure, the **unit of observation** appears to be the **Household**. The variables consistently describe household characteristics, and each observation clearly corresponds to a single household. There is no evidence suggesting multiple units of observation.\n",
    "\n",
    "Unique ID = **hhid**\n",
    "\n",
    "## Identify and Fix Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1111b4ec-b2b4-4a68-9e76-1a0fc9365ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Dataset has 2 duplicates.\n"
     ]
    }
   ],
   "source": [
    "# Identify duplicate by \"hhid\" column\n",
    "duplicates = df['hhid'].duplicated().sum()\n",
    "\n",
    "# Display the number of duplicates in the dataset\n",
    "print(f\"The Dataset has {duplicates} duplicates.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0805c10b-8426-40f9-a712-8397c1d0e840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new number of duplicated observation is: 0.\n"
     ]
    }
   ],
   "source": [
    "# Drop Duplicates -- the code will drop duplicates \n",
    "df.drop_duplicates(subset = ['hhid'], ignore_index = True, inplace = True)\n",
    "\n",
    "# Check if indeed duplicates have been deleted \n",
    "new_duplicates = df['hhid'].duplicated().sum()\n",
    "print(f\"The new number of duplicated observation is: {new_duplicates}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9ed997-2e4f-4ec2-87d2-2c2358b6bfb9",
   "metadata": {},
   "source": [
    "## Clean the Data  \n",
    "\n",
    "### Replace numeric values representing missing data (-88) with missings.\n",
    "\n",
    "To address the presence of **-88** as a missing value indicator, these values will be replaced with **NaN**, the standard Python representation for missing data. Before applying the replacement, we will display the first five rows of a representative column containing **-88** to serve as a baseline for verification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2b86075-8190-44e4-b74d-9982511279b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     1\n",
      "1   -88\n",
      "2     0\n",
      "3     0\n",
      "4     0\n",
      "Name: assoc, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Display the first five rows of \"assoc\" column\n",
    "print(df['assoc'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b1e5ca8-bb8d-4cd5-a754-b1a551fe1a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1.0\n",
      "1    NaN\n",
      "2    0.0\n",
      "3    0.0\n",
      "4    0.0\n",
      "Name: assoc, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Replace numeric values representing missing data (-88) with NaN values.\n",
    "df.replace(-88, np.nan, inplace = True)\n",
    "\n",
    "# Display the \"assoc\" column again to check if the changes made are successful\n",
    "print(df['assoc'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2812fb11-8feb-454c-baac-88608099ede0",
   "metadata": {},
   "source": [
    "The **-88** values have successfully been replaced with **NaN** as indicated in the `assoc` column snipet above. \n",
    "\n",
    "### Extend the values in `crop` column by adding the two most used categories from `crop_other`.\n",
    "\n",
    "Before anything else, It is import to create a **Frequency Table** for `crop_other` column to check its **unique** values and their corresponding frequencies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03fde8b3-d108-4d3a-a14f-d5dfa19984d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The unique values for crop_other are:\n",
      " crop_other\n",
      "NaN               1659\n",
      "sesame              31\n",
      "Sesame              25\n",
      "Sesame.             24\n",
      "Coconut             15\n",
      "Coconut.             2\n",
      "Coconut trees        1\n",
      "Coconut trees.       1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Creating frequency distribution table for crop_other\" column\n",
    "crop_other_freq = df['crop_other'].value_counts(dropna = False)\n",
    "\n",
    "# Display the unique values\n",
    "print(f\"The unique values for crop_other are:\\n {crop_other_freq}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43096387-1780-4faf-9883-5fb271343fdc",
   "metadata": {},
   "source": [
    "As evidenced by the table, this column exhibits inconsistent data entries. It contains a mix of intended missing value indicators, specific entries like **Seseme** and **Coconut**, and numerous typographical errors. Therefore, it is essential to clean this column before proceeding with any data extensions or modifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12034fa7-06bc-4d61-8276-d282f3fd429b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new frequency table for crop_other is:\n",
      " crop_other\n",
      "NaN        1659\n",
      "Sesame       80\n",
      "Coconut      19\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Map old values to new values - Cleaning \"crop_other\" column\n",
    "map = {'sesame': 'Sesame', 'Sesame.': 'Sesame', 'Sesame': 'Sesame', 'Coconut.':\\\n",
    "       'Coconut', 'Coconut trees': 'Coconut', 'Coconut trees.': 'Coconut', 'Coconut': 'Coconut'}\n",
    "\n",
    "# Map Inconsistent values to correct values\n",
    "df['crop_other'] = df['crop_other'].map(map)\n",
    "\n",
    "# Display the new frequency table to check if the column has been cleaned\n",
    "crop_other_freq = df['crop_other'].value_counts(dropna = False)\n",
    "print(f\"The new frequency table for crop_other is:\\n {crop_other_freq}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2b7712-70ca-4c2b-8ec1-03c8be3b2eaa",
   "metadata": {},
   "source": [
    "The `crop_other` column is now cleaned and ready for further analysis. The next step is to augment the `crop` column by incorporating the two most common entries from `crop_other`. To better understand the interplay between these columns, the following is a table snippet that specifically highlights instances where `crop_other` contains **Sesame** or **Coconut**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c998674-e2de-4fb7-9506-13e4dbe90068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      crop crop_other\n",
      "1     99.0    Coconut\n",
      "2     99.0     Sesame\n",
      "1095  99.0     Sesame\n",
      "1261  99.0     Sesame\n",
      "666   99.0     Sesame\n",
      "1749  99.0    Coconut\n",
      "1266  99.0     Sesame\n",
      "668   99.0     Sesame\n",
      "66    99.0     Sesame\n",
      "1401  99.0    Coconut\n"
     ]
    }
   ],
   "source": [
    "df_crop = df[df['crop_other'].isin(['Sesame', 'Coconut'])][['crop', 'crop_other']]\n",
    "print(df_crop.sample(10, random_state = 45))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf20efdb-a517-4f3f-ba10-419524c0439a",
   "metadata": {},
   "source": [
    "Given that the `crop` column is intended as a numerical representation of the categorical values in `crop_other`, it's crucial that each unique category in `crop_other` has a unique numerical code in `crop`. To integrate 'Sesame' and 'Coconut' from crop_other into crop, it makes sense to assign them two previously unused numerical codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7439612-a58f-4137-929c-6c83f711f626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      crop crop_other\n",
      "1     41.0    Coconut\n",
      "2     40.0     Sesame\n",
      "1095  40.0     Sesame\n",
      "1261  40.0     Sesame\n",
      "666   40.0     Sesame\n",
      "1749  41.0    Coconut\n",
      "1266  40.0     Sesame\n",
      "668   40.0     Sesame\n",
      "66    40.0     Sesame\n",
      "1401  41.0    Coconut\n"
     ]
    }
   ],
   "source": [
    "### Extend the values in crop column by adding the two most used categories from crop_other\n",
    "df['crop'] = df['crop'].mask(df['crop_other'] == 'Sesame', 40)\n",
    "df['crop'] = df['crop'].mask(df['crop_other'] == 'Coconut', 41)\n",
    "\n",
    "# Verify if the values have indeed been changed\n",
    "df_crop = df[df['crop_other'].isin(['Sesame', 'Coconut'])][['crop', 'crop_other']]\n",
    "print(df_crop.sample(10, random_state = 45))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1d6340e-5b82-4b5c-9dff-b82734ae0fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The Unique values for 'crop' column are:\n",
      " [77. 41. 40.  6.  4.  9.  5. 34.  1. 15. nan 11. 32. 39.  3.  8. 21. 20.\n",
      " 24. 18. 10. 17. 31.  2. 13.]\n"
     ]
    }
   ],
   "source": [
    "# Display unique values for crop column to verify if \"99\" is realy gone\n",
    "crop_unique = df['crop'].unique()\n",
    "\n",
    "# Display the unique values\n",
    "print(f\"\\nThe Unique values for 'crop' column are:\\n {crop_unique}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198238b3-8156-4a55-9a39-7b806a677ae2",
   "metadata": {},
   "source": [
    "`crop` column and `crop_other` columns have successfully been cleaned.\n",
    "\n",
    "### Check and document if there are numeric variable that have outliers\n",
    "\n",
    "The following activities will check for otliers in **Consumption** and **Area variables**.\n",
    "\n",
    "**Consumption Varaibles**: `food_cons` and `nonfood_cons`\n",
    "\n",
    "**Area Variables**: `ar_farm`\n",
    "\n",
    "The first step is to generate the summary statistics for the three columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae6d51f8-3e59-4cb0-83af-44d26306cd1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary Statistics for 'Consumption' and 'Area' variables: \n",
      "\n",
      "           food_cons  nonfood_cons      ar_farm\n",
      "count  1.758000e+03  1.758000e+03  1620.000000\n",
      "mean   6.392233e+05  1.468731e+05     1.321132\n",
      "std    5.131717e+05  2.510197e+05     1.061838\n",
      "min    5.096000e+03  0.000000e+00     0.125000\n",
      "25%    2.616250e+05  2.347750e+04     1.000000\n",
      "50%    5.174000e+05  6.993300e+04     1.214083\n",
      "75%    8.580000e+05  1.665750e+05     2.000000\n",
      "max    4.903600e+06  4.108400e+06    32.375556\n"
     ]
    }
   ],
   "source": [
    "df_stats = df[['food_cons', 'nonfood_cons', 'ar_farm']].describe()\n",
    "print(f\"\\nSummary Statistics for 'Consumption' and 'Area' variables: \\n\\n {df_stats}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5d0547-ca2b-43f7-b6b7-0d951df14652",
   "metadata": {},
   "source": [
    "The summary statistics will facilitate the calculation of **interquartile** ranges (IQRs). These **IQR**s will subsequently be used to define **upper** and **lower** outlier **thresholds**. Data points that fall beyond these thresholds will be flagged as **outliers**.\n",
    "\n",
    "#### Check for outliers in `food_cons` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "171c9b69-32cc-472a-ae7b-4b6fb2f321db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " The Outliers for 'food_cons' columns are:\n",
      " 1       1955200.0\n",
      "6       1842360.0\n",
      "9       1903200.0\n",
      "24      2002000.0\n",
      "35      2243800.0\n",
      "          ...    \n",
      "1562    2405000.0\n",
      "1598    1801800.0\n",
      "1607    2246400.0\n",
      "1626    1874600.0\n",
      "1633    2150200.0\n",
      "Name: food_cons, Length: 65, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Determine the first Quartile (Q1) and Third Quartile (Q3)\n",
    "Q1 = df_stats.loc['25%', 'food_cons']\n",
    "Q3 = df_stats.loc['75%', 'food_cons']\n",
    "\n",
    "# Calculate \"Interquatile\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define the multiplier\n",
    "multiplier = 1.5\n",
    "\n",
    "# Calculate \"Upper\" and \"Lower\" Thresholds using IQR and multiplier\n",
    "upper_threshold = Q3 + (IQR * multiplier)\n",
    "lower_threshold = Q1 - (IQR * multiplier)\n",
    "\n",
    "# Find Outliers\n",
    "outliers = df[(df['food_cons'] > upper_threshold) | (df['food_cons'] < lower_threshold)]['food_cons']\n",
    "\n",
    "# Display Outliers\n",
    "print(f\"\\n The Outliers for 'food_cons' columns are:\\n {outliers}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a369b79a-c251-4ad0-8737-9fceb5f907b2",
   "metadata": {},
   "source": [
    "The output indicates that the column `food_cons` has **65** outliers.\n",
    "\n",
    "#### Check for outliers in `nonfood_cons` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "08c7ce16-f618-42a5-a829-a568788615a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The Outliers for 'nonfood_cons' column are: \n",
      " 9       553500\n",
      "22      567900\n",
      "32      417400\n",
      "41      396300\n",
      "48      630600\n",
      "         ...  \n",
      "1685    576300\n",
      "1714    386800\n",
      "1719    454800\n",
      "1720    445700\n",
      "1723    641400\n",
      "Name: nonfood_cons, Length: 157, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Determine the first Quartile (Q1) and Third Quartile (Q3)\n",
    "Q1 = df_stats.loc['25%', 'nonfood_cons']\n",
    "Q3 = df_stats.loc['75%', 'nonfood_cons']\n",
    "\n",
    "# Calculate \"Interquatile\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define the multiplier\n",
    "multiplier = 1.5\n",
    "\n",
    "# Calculate \"Upper\" and \"Lower\" Thresholds using IQR and multiplier\n",
    "upper_threshold = Q3 + (IQR * multiplier)\n",
    "lower_threshold = Q1 - (IQR * multiplier)\n",
    "\n",
    "# Find Outliers\n",
    "outliers = df[(df['nonfood_cons'] > upper_threshold) | (df['nonfood_cons'] < lower_threshold)]['nonfood_cons']\n",
    "\n",
    "# Display Outliers\n",
    "print(f\"\\nThe Outliers for 'nonfood_cons' column are: \\n {outliers}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e67c9e8-c185-4a2d-84eb-cc67ef81ccb0",
   "metadata": {},
   "source": [
    "`nonfood` column has **157** outliers.\n",
    "\n",
    "#### Check for outliers in `ar_farm` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17e7cc0b-eb71-4091-a017-0723f9712879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The Outliers for 'ar_farm' column are:\n",
      " 132      4.046945\n",
      "183      6.070417\n",
      "386      4.856333\n",
      "499      5.261028\n",
      "639      3.642250\n",
      "656      4.046945\n",
      "673      6.475111\n",
      "745      4.046945\n",
      "998      4.046945\n",
      "1001     6.475111\n",
      "1003     3.642250\n",
      "1006     6.879806\n",
      "1147     4.046945\n",
      "1153     4.451639\n",
      "1271     4.451639\n",
      "1345    32.375556\n",
      "1453     6.070417\n",
      "1497     4.046945\n",
      "1503     4.046945\n",
      "1607     3.642250\n",
      "1609     4.046945\n",
      "Name: ar_farm, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Determine the first Quartile (Q1) and Third Quartile (Q3)\n",
    "Q1 = df_stats.loc['25%', 'ar_farm']\n",
    "Q3 = df_stats.loc['75%', 'ar_farm']\n",
    "\n",
    "# Calculate \"Interquatile\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define the multiplier\n",
    "multiplier = 1.5\n",
    "\n",
    "# Calculate \"Upper\" and \"Lower\" Thresholds using IQR and multiplier\n",
    "upper_threshold = Q3 + (IQR * multiplier)\n",
    "lower_threshold = Q1 - (IQR * multiplier)\n",
    "\n",
    "# Find Outliers\n",
    "outliers = df[(df['ar_farm'] > upper_threshold) | (df['ar_farm'] < lower_threshold)]['ar_farm']\n",
    "\n",
    "# Display Outliers\n",
    "print(f\"\\nThe Outliers for 'ar_farm' column are:\\n {outliers}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65c3161-1c9b-41c4-b9c9-cfe666e424af",
   "metadata": {},
   "source": [
    "`ar_farm`column has **21** outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94afcb2-7855-4ca8-8fa1-06a083f0a4fa",
   "metadata": {},
   "source": [
    "## Saving the cleaned Dataset\n",
    "\n",
    "The cleaned dataset will be saved in Data/Intermediate folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a4da7d22-6c62-4208-9277-b9a4007a6ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Data/Intermediate/TZA_CCT_baseline_new.csv\", encoding = \"utf8\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472fff7d-ac87-4cf3-bb11-d16f9162e296",
   "metadata": {},
   "source": [
    "# Preparing Data for Reproducible Analytics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
